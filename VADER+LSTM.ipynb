{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementasi Metode VADER-LSTM dalam Pengujian Pengaruh Sentimen Investor terhadap Prediksi Harga Saham"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljaywiikl4zP",
        "outputId": "49b92a99-8e67-4e03-e2b4-4c7eb7f33112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\ravie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ravie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ravie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "import nltk\n",
        "import unicodedata\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as dt\n",
        "from matplotlib.dates import DateFormatter\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras import models as md\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoB1vjA469iM"
      },
      "outputs": [],
      "source": [
        "company = \"TSLA\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Tweet Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "s4gocCIkkUkY",
        "outputId": "e5a6b992-2edf-4d84-d7ee-5fa4f03d4a2f"
      },
      "outputs": [],
      "source": [
        "all_tweets = pd.read_csv(\"stock_tweets.csv\")\n",
        "print(all_tweets.shape)\n",
        "all_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hm4AXNZCk2el",
        "outputId": "319b5eda-637b-4401-be8a-d5843f2fb11b"
      },
      "outputs": [],
      "source": [
        "tweet_df = all_tweets[all_tweets['Stock Name'] == company]\n",
        "tweet_df = tweet_df.drop(['Company Name', 'Stock Name'], axis=1)\n",
        "tweet_df['Date'] = pd.to_datetime(tweet_df['Date']).dt.date\n",
        "tweet_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pre-processing the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_df = tweet_df.copy()\n",
        "processed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_tweet(tweet):\n",
        "    '''\n",
        "    Takes a tweet as an input and output the list of tokens.\n",
        "    '''\n",
        "    \n",
        "    import emoji\n",
        "    import re\n",
        "    from nltk import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    \n",
        "    # Initialization\n",
        "    new_tweet = tweet\n",
        "    \n",
        "    ## Changes on string\n",
        "    \n",
        "    # Remove urls\n",
        "    new_tweet = re.sub(r'https?://[^ ]+', '', new_tweet)\n",
        "    \n",
        "    # Remove usernames\n",
        "    new_tweet = re.sub(r'@[^ ]+', '', new_tweet)\n",
        "    \n",
        "    # Remove hashtags\n",
        "    new_tweet = re.sub(r'#', '', new_tweet)\n",
        "    \n",
        "    # Character normalization\n",
        "    new_tweet = re.sub(r'([A-Za-z])\\1{2,}', r'\\1', new_tweet)\n",
        "    \n",
        "    # Emoji transformation\n",
        "    new_tweet = emoji.demojize(new_tweet)\n",
        "    \n",
        "    # Punctuation and special characters\n",
        "    new_tweet = re.sub(r' 0 ', 'zero', new_tweet)\n",
        "    new_tweet = re.sub(r'[^A-Za-z ]', '', new_tweet)\n",
        "    \n",
        "    # Lower casing\n",
        "    new_tweet = new_tweet.lower()\n",
        "    \n",
        "    \n",
        "    ## Changes on tokens\n",
        "    \n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(new_tweet)\n",
        "    \n",
        "    porter = PorterStemmer()\n",
        "\n",
        "    for token in tokens:\n",
        "        # Stopwords removal\n",
        "        if token in stopwords.words('english'):\n",
        "            tokens.remove(token)\n",
        "        # Stemming\n",
        "        token = porter.stem(token)\n",
        "    \n",
        "    return ' '.join(tokens)\n",
        "    # return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for indx, row in processed_df.T.items():\n",
        "    try:\n",
        "        processed_df.at[indx, 'Tweet'] = preprocess_tweet(processed_df.at[indx, 'Tweet'])\n",
        "    except TypeError:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_df.to_csv('tweet_processed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Labeling the tweets with VADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_df = pd.read_csv('tweet_processed.csv')\n",
        "processed_df['Date'] = pd.to_datetime(processed_df['Date'])\n",
        "processed_df['Tweet'] = processed_df['Tweet'].astype(str)\n",
        "processed_df['Date'] = pd.to_datetime(processed_df['Date'])\n",
        "processed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "for indx, row in processed_df.T.items():\n",
        "    try:\n",
        "        sentence_sentiment = sentiment_analyzer.polarity_scores(processed_df.loc[indx, 'Tweet'])\n",
        "        processed_df.at[indx, 'Negative'] = sentence_sentiment['neg']\n",
        "        processed_df.at[indx, 'Neutral'] = sentence_sentiment['neu']\n",
        "        processed_df.at[indx, 'Positive'] = sentence_sentiment['pos']\n",
        "        processed_df.at[indx, 'Compound'] = sentence_sentiment['compound']\n",
        "    except TypeError:\n",
        "        print (processed_df.loc[indx, 'Tweet'])\n",
        "        print (indx)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_df.to_csv('tweet_processed_labeled.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_df = pd.read_csv('tweet_processed_labeled.csv')\n",
        "processed_df['Date'] = pd.to_datetime(processed_df['Date'])\n",
        "processed_df['Date'] = processed_df['Date'].dt.date\n",
        "processed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeled_tweets_df = processed_df.copy()\n",
        "\n",
        "for indx, row in processed_df.T.items():\n",
        "    if (processed_df.at[indx, 'Compound'] > 0.5):\n",
        "        labeled_tweets_df.at[indx, 'Sentiment'] = 'Positive'\n",
        "    elif (processed_df.at[indx, 'Compound'] < -0.5):\n",
        "        labeled_tweets_df.at[indx, 'Sentiment'] = 'Negative'\n",
        "    else:\n",
        "        labeled_tweets_df.at[indx, 'Sentiment'] = 'Neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeled_tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "bar_colors = ['grey', 'green', 'red']\n",
        "ax.bar(['Neutral', 'Positive', 'Negative'], labeled_tweets_df['Sentiment'].value_counts(), color=bar_colors)\n",
        "ax.set(xlabel=\"Sentimen\", ylabel=\"Count\", title=f\"{company} Sentiment Result\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "daily_sentiments_df = labeled_tweets_df.groupby([labeled_tweets_df['Date']]).mean(numeric_only=True)\n",
        "daily_sentiments_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax.plot(daily_sentiments_df['Compound'], color='#008B8B')\n",
        "ax.set(xlabel=\"Date\", ylabel=\"Sentiment\", title=f\"{company} Daily Sentiment\")\n",
        "ax.xaxis.set_major_locator(dt.MonthLocator())\n",
        "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Grouping sentiments by day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "gjvqS1Ijw7H3",
        "outputId": "f5a4c12e-03f7-4550-ba6f-4d5de8f1aa5f"
      },
      "outputs": [],
      "source": [
        "daily_sentiments_df = processed_df.groupby([processed_df['Date']]).mean(numeric_only=True)\n",
        "daily_sentiments_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "V8kKkLSulEMe",
        "outputId": "3fb9f070-4d05-41c7-f132-3395e3c37618"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax.plot(daily_sentiments_df['Compound'], color='#008B8B')\n",
        "ax.set(xlabel=\"Date\", ylabel=\"Score\", title=f\"{company} Daily Sentiment\")\n",
        "ax.xaxis.set_major_locator(dt.MonthLocator())\n",
        "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Stock Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4S5DD9P95z9x",
        "outputId": "c3b7c868-417f-4961-de3a-33c060ab4e5d"
      },
      "outputs": [],
      "source": [
        "all_stocks = pd.read_csv(\"stock_yfinance_data.csv\")\n",
        "all_stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "L72o-YzF7zw7",
        "outputId": "675f77de-f30c-4760-b7d6-c09e08520ce8"
      },
      "outputs": [],
      "source": [
        "stock_df = all_stocks[all_stocks['Stock Name'] == company]\n",
        "stock_df = stock_df.drop('Stock Name', axis=1)\n",
        "stock_df['Date'] = pd.to_datetime(stock_df['Date']).dt.date\n",
        "stock_df = stock_df.set_index(\"Date\")\n",
        "stock_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stock_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "K0pNKNfZCCKS",
        "outputId": "48e7c276-e5da-4e91-e616-627d072c8c12"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax.plot(stock_df['Close'], color='#008B8B')\n",
        "ax.set(xlabel=\"Date\", ylabel=\"USD\", title=f\"{company} Stock Price\")\n",
        "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "QNbSzCPxogZP",
        "outputId": "a298b6b6-a8c8-4d01-f091-090cf6fbe619"
      },
      "outputs": [],
      "source": [
        "dataset_df = stock_df.copy()\n",
        "dataset_df = dataset_df.join(daily_sentiments_df, how=\"left\", on=\"Date\")\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(dataset_df[['Close', 'Compound']].values)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(scaled_data, label=[\"Closing Price\", 'Sentiment'])\n",
        "ax.set(xlabel=\"Date\", ylabel=\"Scaled Data\", title=f\"{company} Scaled Price Overlaid with Daily Sentiment\")\n",
        "ax.legend()\n",
        "# ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SplitData(data, train_size, timestep):\n",
        "    data_values = data.values\n",
        "    training_data_len = math.ceil(len(data)* train_size)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    if (len(data_values.shape) == 1):\n",
        "        scaled_data = scaler.fit_transform(data_values.reshape(-1,1))\n",
        "    else:\n",
        "        scaled_data = scaler.fit_transform(data_values)\n",
        "        scaled_index = scaler.fit_transform(data_values[:, 0:1].flatten().reshape(-1,1))\n",
        "\n",
        "    train_data = scaled_data[0: training_data_len, :]\n",
        "    test_data = scaled_data[training_data_len-timestep: , :]\n",
        "\n",
        "    train_data_x = train_data[0: training_data_len, :]\n",
        "    train_data_y = train_data[0: training_data_len, 0:1]\n",
        "\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(timestep, len(train_data_x)):\n",
        "        x_train.append(train_data_x[i-timestep:i])\n",
        "        y_train.append(train_data_y[i][0])\n",
        "\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
        "\n",
        "    test_data = scaled_data[training_data_len-timestep: , : ]\n",
        "    x_test = []\n",
        "    if (len(data_values.shape) == 1):\n",
        "        y_test = data_values[training_data_len:]\n",
        "    else:\n",
        "        y_test = data_values[training_data_len: , 0]\n",
        "\n",
        "    for i in range(timestep, len(test_data)):\n",
        "        x_test.append(test_data[i-timestep:i])\n",
        "\n",
        "    x_test = np.array(x_test)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TrainModel(x_data, y_data, epoch):\n",
        "\n",
        "    regressor = Sequential()\n",
        "    regressor.add(LSTM(units=64, return_sequences=True, input_shape=(x_data.shape[1], x_data.shape[2])))\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "    regressor.add(LSTM(units=64, return_sequences=False))\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "    regressor.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "    regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
        "    history = regressor.fit(x_data, y_data, batch_size=1, epochs=epoch, validation_split=0.2)\n",
        "\n",
        "    return regressor, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PlotTrainingMetrics(history):\n",
        "    history_data = history.history\n",
        "    \n",
        "    loss_values = history_data['loss']\n",
        "    val_loss_values = history_data['val_loss']\n",
        "    mae_values = history_data['mae']\n",
        "    val_mae_values = history_data['val_mae']\n",
        "    rmse_values = np.sqrt(history_data['loss'])\n",
        "    val_rmse_values = np.sqrt(history_data['val_loss'])\n",
        "    epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "    gs = fig.add_gridspec(1, 3, wspace=0)\n",
        "    (ax1, ax2, ax3) = gs.subplots(sharey=True)\n",
        "    fig.suptitle('Training and validation metrics')\n",
        "    fig.supxlabel('epochs')\n",
        "\n",
        "    ax1.plot(epochs, mae_values, color = 'blue', label='Training MAE')\n",
        "    ax1.plot(epochs, val_mae_values, color='red', label='Validation MAE')\n",
        "    ax1.set_title('MAE')\n",
        "    ax1.set_xticks(epochs)\n",
        "    ax1.xaxis.set_major_locator(ticker.MultipleLocator(len(loss_values)/5))\n",
        "    ax1.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
        "    ax1.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax1.yaxis.grid(True, alpha=0.5)\n",
        "    ax1.set_ylabel('value')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(epochs, loss_values, color = 'blue', label='Training loss')\n",
        "    ax2.plot(epochs, val_loss_values, color='red', label='Validation loss')\n",
        "    ax2.set_title('Loss (MSE)')\n",
        "    ax2.set_xticks(epochs)\n",
        "    ax2.xaxis.set_major_locator(ticker.MultipleLocator(len(loss_values)/5))\n",
        "    ax2.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
        "    ax2.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax2.yaxis.grid(True, alpha=0.5)\n",
        "    ax2.legend()\n",
        "\n",
        "    ax3.plot(epochs, rmse_values, color = 'blue', label='Training RMSE')\n",
        "    ax3.plot(epochs, val_rmse_values, color='red', label='Validation RMSE')\n",
        "    ax3.set_title('RMSE')\n",
        "    ax3.set_xticks(epochs)\n",
        "    ax3.xaxis.set_major_locator(ticker.MultipleLocator(len(loss_values)/5))\n",
        "    ax3.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
        "    ax3.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax3.yaxis.grid(True, alpha=0.5)\n",
        "    ax3.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PlotPredictions(data, prediction):\n",
        "    train_plot = data[:len(data)-len(prediction)]\n",
        "    validation_plot = data[len(data)-len(prediction):].copy()\n",
        "    validation_plot['Predictions'] = prediction\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    ax.set_title('Model and Predictions')\n",
        "    ax.set_ylabel('Closing price (USD)')\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.plot(train_plot)\n",
        "    ax.plot(validation_plot[['Close', 'Predictions']])\n",
        "    ax.xaxis.set_major_locator(dt.MonthLocator())\n",
        "    ax.xaxis.set_minor_locator(dt.MonthLocator(bymonthday=15))\n",
        "    ax.xaxis.set_major_formatter(dt.DateFormatter('%b'))\n",
        "    ax.grid(alpha=0.5, which='both')\n",
        "    ax.legend(['Train', 'Validation', 'Predictions'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uiks1f82oTPX"
      },
      "source": [
        "### LSTM without Sentiment Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdunwbHQR4lK"
      },
      "outputs": [],
      "source": [
        "close_prices = dataset_df['Close']\n",
        "\n",
        "train_portion = 0.8\n",
        "timestep = 60\n",
        "\n",
        "\n",
        "x_train, y_train, x_test, y_test, scaler = SplitData(close_prices, train_portion, timestep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "singleModel, history_single = TrainModel(x_train, y_train, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "singleModel.save('saved_model/single-features.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "singleModel = md.load_model('saved_model/single-features.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "singleModel.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "singleModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdz6jcJNSTSw",
        "outputId": "00e7ad9d-01a5-4328-bf75-a65be7df38ea"
      },
      "outputs": [],
      "source": [
        "predictions_single = singleModel.predict(x_test)\n",
        "predictions_single = scaler.inverse_transform(predictions_single)\n",
        "\n",
        "mae = np.mean(np.abs(predictions_single - y_test))\n",
        "mse = np.mean((predictions_single - y_test)**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mape = np.mean(np.abs((y_test - predictions_single)/y_test)) * 100\n",
        "mae, mse, rmse, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PlotTrainingMetrics(history_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PlotPredictions(dataset_df.filter(['Close']), predictions_single)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ojots9FfJU2a"
      },
      "source": [
        "### LSTM with User Sentiment Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2OrcJx0VM4X"
      },
      "outputs": [],
      "source": [
        "combined_data = dataset_df[['Close', 'Compound']].copy()\n",
        "\n",
        "train_portion = 0.8\n",
        "timestep = 60\n",
        "\n",
        "x_train, y_train, x_test, y_test, scaler = SplitData(combined_data, train_portion, timestep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentimentModel, history_sentiment = TrainModel(x_train, y_train, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentimentModel.save('saved_model/multi-features.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentimentModel = md.load_model('saved_model/multi-features.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = sentimentModel.predict(x_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae = np.mean(np.abs(predictions - y_test))\n",
        "mse = np.mean((predictions - y_test)**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mape = np.mean(np.abs((y_test - predictions)/y_test)) * 100\n",
        "mae, mse, rmse, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PlotTrainingMetrics(history_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PlotPredictions(dataset_df.filter(['Close']), predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine Tuning with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TrainModelFineTune(x_data, y_data, epoch, neuron_units):\n",
        "\n",
        "    regressor = Sequential()\n",
        "    regressor.add(LSTM(units=neuron_units, return_sequences=True, input_shape=(x_data.shape[1], x_data.shape[2])))\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "    regressor.add(LSTM(units=neuron_units, return_sequences=False))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "    regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    history = regressor.fit(x_data, y_data, batch_size=1, epochs=epoch, validation_split=0.2)\n",
        "\n",
        "    return regressor, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine Tune Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = [5, 10, 20, 30, 40, 50]\n",
        "\n",
        "epoch_finetune_history = []\n",
        "epoch_finetune_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = dataset_df[['Close', 'Compound']].copy()\n",
        "\n",
        "train_portion = 0.8\n",
        "timestep = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(epochs)):\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    ax.set_title('Loss value for ' + str(epochs[i]) + ' epochs')\n",
        "    ax.set_xlabel('epochs')\n",
        "    ax.set_ylabel('error value')\n",
        "    ax.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax.yaxis.grid(True, alpha=0.5)\n",
        "\n",
        "    for j in range(10):\n",
        "\n",
        "        x_train, y_train, x_test, y_test, scaler = SplitData(combined_data, train_portion, timestep)\n",
        "\n",
        "        start_time = time.time()\n",
        "        sentimentModel, history = TrainModelFineTune(x_train, y_train, epochs[i], 32)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "\n",
        "        predictions = sentimentModel.predict(x_test)\n",
        "        predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "        mae = np.mean(np.abs(predictions - y_test))\n",
        "        mse = np.mean((predictions - y_test)**2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = np.mean(np.abs((y_test - predictions)/y_test)) * 100\n",
        "\n",
        "        epoch_finetune_test.append([epochs[i], j, mae, mse, rmse, mape, training_time])\n",
        "\n",
        "        history_data = history.history\n",
        "    \n",
        "        loss_values = history_data['loss']\n",
        "        val_loss_values = history_data['val_loss']\n",
        "\n",
        "        epoch_finetune_history.append([epochs[i], j, history_data['loss'], history_data['val_loss'], history_data['mae'], history_data['val_mae'], training_time])\n",
        "\n",
        "        ax.plot(loss_values, color = 'blue')\n",
        "        ax.plot(val_loss_values, color='red')\n",
        "\n",
        "    plt.savefig('epoch_finetune_data/'+ str(epochs[i]) +'_epochs_diagnostic.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_test_finetuning = pd.DataFrame(epoch_finetune_test, columns=['#epoch', '#try', 'MAE', 'MSE', 'RMSE', 'MAPE', 'train_time'])\n",
        "epoch_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_test_finetuning.to_csv('epoch_finetune_data/finetuning_test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#epoch</th>\n",
              "      <th>#try</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>train_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>16.452995</td>\n",
              "      <td>417.084625</td>\n",
              "      <td>20.422650</td>\n",
              "      <td>5.792440</td>\n",
              "      <td>27.497829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>14.595786</td>\n",
              "      <td>337.351724</td>\n",
              "      <td>18.367137</td>\n",
              "      <td>5.085739</td>\n",
              "      <td>26.651451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>21.534943</td>\n",
              "      <td>652.194895</td>\n",
              "      <td>25.538107</td>\n",
              "      <td>7.580885</td>\n",
              "      <td>26.448623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>16.364322</td>\n",
              "      <td>411.876037</td>\n",
              "      <td>20.294729</td>\n",
              "      <td>5.764117</td>\n",
              "      <td>26.594965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16.382885</td>\n",
              "      <td>412.905221</td>\n",
              "      <td>20.320069</td>\n",
              "      <td>5.772575</td>\n",
              "      <td>30.561859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>15.202103</td>\n",
              "      <td>357.268913</td>\n",
              "      <td>18.901558</td>\n",
              "      <td>5.198762</td>\n",
              "      <td>28.937516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>16.426257</td>\n",
              "      <td>415.624994</td>\n",
              "      <td>20.386883</td>\n",
              "      <td>5.782871</td>\n",
              "      <td>27.776019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>16.164125</td>\n",
              "      <td>398.580501</td>\n",
              "      <td>19.964481</td>\n",
              "      <td>5.518425</td>\n",
              "      <td>27.554009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>17.525272</td>\n",
              "      <td>461.204532</td>\n",
              "      <td>21.475673</td>\n",
              "      <td>6.175580</td>\n",
              "      <td>27.610307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>21.864256</td>\n",
              "      <td>677.010242</td>\n",
              "      <td>26.019420</td>\n",
              "      <td>7.695033</td>\n",
              "      <td>28.541749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>17.827169</td>\n",
              "      <td>480.736734</td>\n",
              "      <td>21.925709</td>\n",
              "      <td>6.272033</td>\n",
              "      <td>46.911663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>15.938373</td>\n",
              "      <td>401.929858</td>\n",
              "      <td>20.048188</td>\n",
              "      <td>5.583473</td>\n",
              "      <td>47.243852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>15.556178</td>\n",
              "      <td>375.885095</td>\n",
              "      <td>19.387756</td>\n",
              "      <td>5.320374</td>\n",
              "      <td>46.910299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>14.731575</td>\n",
              "      <td>342.775503</td>\n",
              "      <td>18.514197</td>\n",
              "      <td>5.098338</td>\n",
              "      <td>46.541039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>17.739100</td>\n",
              "      <td>481.829610</td>\n",
              "      <td>21.950618</td>\n",
              "      <td>6.222562</td>\n",
              "      <td>50.384203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>15.212959</td>\n",
              "      <td>365.501046</td>\n",
              "      <td>19.118082</td>\n",
              "      <td>5.306121</td>\n",
              "      <td>43.986791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>17.228120</td>\n",
              "      <td>454.235900</td>\n",
              "      <td>21.312811</td>\n",
              "      <td>6.061339</td>\n",
              "      <td>46.852746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>15.298756</td>\n",
              "      <td>363.875359</td>\n",
              "      <td>19.075517</td>\n",
              "      <td>5.262288</td>\n",
              "      <td>53.880965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>14.858807</td>\n",
              "      <td>341.214858</td>\n",
              "      <td>18.472002</td>\n",
              "      <td>5.093658</td>\n",
              "      <td>48.333719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>16.188049</td>\n",
              "      <td>408.209120</td>\n",
              "      <td>20.204186</td>\n",
              "      <td>5.681867</td>\n",
              "      <td>46.612864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>15.270353</td>\n",
              "      <td>362.482477</td>\n",
              "      <td>19.038973</td>\n",
              "      <td>5.329361</td>\n",
              "      <td>85.930357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>16.571770</td>\n",
              "      <td>422.158831</td>\n",
              "      <td>20.546504</td>\n",
              "      <td>5.825584</td>\n",
              "      <td>85.566376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>19.456797</td>\n",
              "      <td>559.984571</td>\n",
              "      <td>23.663993</td>\n",
              "      <td>6.839865</td>\n",
              "      <td>86.697762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>16.050030</td>\n",
              "      <td>400.387960</td>\n",
              "      <td>20.009697</td>\n",
              "      <td>5.612081</td>\n",
              "      <td>88.900373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>15.008926</td>\n",
              "      <td>347.023459</td>\n",
              "      <td>18.628566</td>\n",
              "      <td>5.151295</td>\n",
              "      <td>85.440735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>16.140782</td>\n",
              "      <td>413.987537</td>\n",
              "      <td>20.346684</td>\n",
              "      <td>5.589469</td>\n",
              "      <td>86.539991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>18.354735</td>\n",
              "      <td>509.563990</td>\n",
              "      <td>22.573524</td>\n",
              "      <td>6.462588</td>\n",
              "      <td>87.350480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>14.908833</td>\n",
              "      <td>347.990727</td>\n",
              "      <td>18.654510</td>\n",
              "      <td>5.191494</td>\n",
              "      <td>87.073279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>17.924737</td>\n",
              "      <td>484.501541</td>\n",
              "      <td>22.011396</td>\n",
              "      <td>6.299236</td>\n",
              "      <td>89.174975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>17.307720</td>\n",
              "      <td>457.635084</td>\n",
              "      <td>21.392407</td>\n",
              "      <td>6.075998</td>\n",
              "      <td>90.272318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>16.985618</td>\n",
              "      <td>440.424619</td>\n",
              "      <td>20.986296</td>\n",
              "      <td>5.958636</td>\n",
              "      <td>135.639912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>16.012969</td>\n",
              "      <td>397.268959</td>\n",
              "      <td>19.931607</td>\n",
              "      <td>5.605768</td>\n",
              "      <td>147.959595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>15.409967</td>\n",
              "      <td>378.313543</td>\n",
              "      <td>19.450284</td>\n",
              "      <td>5.334986</td>\n",
              "      <td>139.433690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>16.656367</td>\n",
              "      <td>431.285417</td>\n",
              "      <td>20.767412</td>\n",
              "      <td>5.791706</td>\n",
              "      <td>143.653253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>16.125668</td>\n",
              "      <td>401.925585</td>\n",
              "      <td>20.048082</td>\n",
              "      <td>5.639519</td>\n",
              "      <td>142.524274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>15.061636</td>\n",
              "      <td>358.378556</td>\n",
              "      <td>18.930889</td>\n",
              "      <td>5.221201</td>\n",
              "      <td>145.552216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>16.878373</td>\n",
              "      <td>436.544124</td>\n",
              "      <td>20.893638</td>\n",
              "      <td>5.918377</td>\n",
              "      <td>135.959963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>20.216380</td>\n",
              "      <td>603.807561</td>\n",
              "      <td>24.572496</td>\n",
              "      <td>7.118248</td>\n",
              "      <td>137.908773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>15.157459</td>\n",
              "      <td>360.750295</td>\n",
              "      <td>18.993428</td>\n",
              "      <td>5.298971</td>\n",
              "      <td>146.101030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>15.000260</td>\n",
              "      <td>355.959713</td>\n",
              "      <td>18.866895</td>\n",
              "      <td>5.202597</td>\n",
              "      <td>138.240873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>17.568640</td>\n",
              "      <td>466.783630</td>\n",
              "      <td>21.605176</td>\n",
              "      <td>6.174636</td>\n",
              "      <td>191.370584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>17.437317</td>\n",
              "      <td>461.494638</td>\n",
              "      <td>21.482426</td>\n",
              "      <td>6.127232</td>\n",
              "      <td>198.127547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>15.397955</td>\n",
              "      <td>369.706346</td>\n",
              "      <td>19.227749</td>\n",
              "      <td>5.367222</td>\n",
              "      <td>188.430756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>15.448308</td>\n",
              "      <td>370.301955</td>\n",
              "      <td>19.243231</td>\n",
              "      <td>5.383957</td>\n",
              "      <td>190.305205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>16.410107</td>\n",
              "      <td>413.077621</td>\n",
              "      <td>20.324311</td>\n",
              "      <td>5.759758</td>\n",
              "      <td>189.220214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>14.685841</td>\n",
              "      <td>339.661235</td>\n",
              "      <td>18.429901</td>\n",
              "      <td>5.089872</td>\n",
              "      <td>188.440455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>40</td>\n",
              "      <td>6</td>\n",
              "      <td>18.917671</td>\n",
              "      <td>533.176569</td>\n",
              "      <td>23.090616</td>\n",
              "      <td>6.660728</td>\n",
              "      <td>186.930768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>15.957208</td>\n",
              "      <td>408.789533</td>\n",
              "      <td>20.218544</td>\n",
              "      <td>5.506396</td>\n",
              "      <td>195.162170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>40</td>\n",
              "      <td>8</td>\n",
              "      <td>17.709993</td>\n",
              "      <td>475.612369</td>\n",
              "      <td>21.808539</td>\n",
              "      <td>6.214644</td>\n",
              "      <td>191.950861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>15.431485</td>\n",
              "      <td>377.971494</td>\n",
              "      <td>19.441489</td>\n",
              "      <td>5.368025</td>\n",
              "      <td>189.029960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>17.937931</td>\n",
              "      <td>484.954440</td>\n",
              "      <td>22.021681</td>\n",
              "      <td>6.293862</td>\n",
              "      <td>251.621316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>15.384080</td>\n",
              "      <td>367.483779</td>\n",
              "      <td>19.169866</td>\n",
              "      <td>5.356815</td>\n",
              "      <td>252.436677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>18.232893</td>\n",
              "      <td>499.372681</td>\n",
              "      <td>22.346648</td>\n",
              "      <td>6.402841</td>\n",
              "      <td>257.872724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>14.916967</td>\n",
              "      <td>347.196082</td>\n",
              "      <td>18.633198</td>\n",
              "      <td>5.203986</td>\n",
              "      <td>244.957552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>18.470940</td>\n",
              "      <td>514.403258</td>\n",
              "      <td>22.680460</td>\n",
              "      <td>6.488050</td>\n",
              "      <td>237.322231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>17.079273</td>\n",
              "      <td>443.215384</td>\n",
              "      <td>21.052681</td>\n",
              "      <td>5.995001</td>\n",
              "      <td>209.100802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>14.881234</td>\n",
              "      <td>343.470972</td>\n",
              "      <td>18.532970</td>\n",
              "      <td>5.169321</td>\n",
              "      <td>237.912954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>15.912704</td>\n",
              "      <td>390.033434</td>\n",
              "      <td>19.749264</td>\n",
              "      <td>5.561161</td>\n",
              "      <td>242.270167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>50</td>\n",
              "      <td>8</td>\n",
              "      <td>17.353007</td>\n",
              "      <td>457.300828</td>\n",
              "      <td>21.384593</td>\n",
              "      <td>6.102271</td>\n",
              "      <td>233.682414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>50</td>\n",
              "      <td>9</td>\n",
              "      <td>16.538022</td>\n",
              "      <td>419.686285</td>\n",
              "      <td>20.486246</td>\n",
              "      <td>5.791815</td>\n",
              "      <td>251.837168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    #epoch  #try        MAE         MSE       RMSE      MAPE  train_time\n",
              "0        5     0  16.452995  417.084625  20.422650  5.792440   27.497829\n",
              "1        5     1  14.595786  337.351724  18.367137  5.085739   26.651451\n",
              "2        5     2  21.534943  652.194895  25.538107  7.580885   26.448623\n",
              "3        5     3  16.364322  411.876037  20.294729  5.764117   26.594965\n",
              "4        5     4  16.382885  412.905221  20.320069  5.772575   30.561859\n",
              "5        5     5  15.202103  357.268913  18.901558  5.198762   28.937516\n",
              "6        5     6  16.426257  415.624994  20.386883  5.782871   27.776019\n",
              "7        5     7  16.164125  398.580501  19.964481  5.518425   27.554009\n",
              "8        5     8  17.525272  461.204532  21.475673  6.175580   27.610307\n",
              "9        5     9  21.864256  677.010242  26.019420  7.695033   28.541749\n",
              "10      10     0  17.827169  480.736734  21.925709  6.272033   46.911663\n",
              "11      10     1  15.938373  401.929858  20.048188  5.583473   47.243852\n",
              "12      10     2  15.556178  375.885095  19.387756  5.320374   46.910299\n",
              "13      10     3  14.731575  342.775503  18.514197  5.098338   46.541039\n",
              "14      10     4  17.739100  481.829610  21.950618  6.222562   50.384203\n",
              "15      10     5  15.212959  365.501046  19.118082  5.306121   43.986791\n",
              "16      10     6  17.228120  454.235900  21.312811  6.061339   46.852746\n",
              "17      10     7  15.298756  363.875359  19.075517  5.262288   53.880965\n",
              "18      10     8  14.858807  341.214858  18.472002  5.093658   48.333719\n",
              "19      10     9  16.188049  408.209120  20.204186  5.681867   46.612864\n",
              "20      20     0  15.270353  362.482477  19.038973  5.329361   85.930357\n",
              "21      20     1  16.571770  422.158831  20.546504  5.825584   85.566376\n",
              "22      20     2  19.456797  559.984571  23.663993  6.839865   86.697762\n",
              "23      20     3  16.050030  400.387960  20.009697  5.612081   88.900373\n",
              "24      20     4  15.008926  347.023459  18.628566  5.151295   85.440735\n",
              "25      20     5  16.140782  413.987537  20.346684  5.589469   86.539991\n",
              "26      20     6  18.354735  509.563990  22.573524  6.462588   87.350480\n",
              "27      20     7  14.908833  347.990727  18.654510  5.191494   87.073279\n",
              "28      20     8  17.924737  484.501541  22.011396  6.299236   89.174975\n",
              "29      20     9  17.307720  457.635084  21.392407  6.075998   90.272318\n",
              "30      30     0  16.985618  440.424619  20.986296  5.958636  135.639912\n",
              "31      30     1  16.012969  397.268959  19.931607  5.605768  147.959595\n",
              "32      30     2  15.409967  378.313543  19.450284  5.334986  139.433690\n",
              "33      30     3  16.656367  431.285417  20.767412  5.791706  143.653253\n",
              "34      30     4  16.125668  401.925585  20.048082  5.639519  142.524274\n",
              "35      30     5  15.061636  358.378556  18.930889  5.221201  145.552216\n",
              "36      30     6  16.878373  436.544124  20.893638  5.918377  135.959963\n",
              "37      30     7  20.216380  603.807561  24.572496  7.118248  137.908773\n",
              "38      30     8  15.157459  360.750295  18.993428  5.298971  146.101030\n",
              "39      30     9  15.000260  355.959713  18.866895  5.202597  138.240873\n",
              "40      40     0  17.568640  466.783630  21.605176  6.174636  191.370584\n",
              "41      40     1  17.437317  461.494638  21.482426  6.127232  198.127547\n",
              "42      40     2  15.397955  369.706346  19.227749  5.367222  188.430756\n",
              "43      40     3  15.448308  370.301955  19.243231  5.383957  190.305205\n",
              "44      40     4  16.410107  413.077621  20.324311  5.759758  189.220214\n",
              "45      40     5  14.685841  339.661235  18.429901  5.089872  188.440455\n",
              "46      40     6  18.917671  533.176569  23.090616  6.660728  186.930768\n",
              "47      40     7  15.957208  408.789533  20.218544  5.506396  195.162170\n",
              "48      40     8  17.709993  475.612369  21.808539  6.214644  191.950861\n",
              "49      40     9  15.431485  377.971494  19.441489  5.368025  189.029960\n",
              "50      50     0  17.937931  484.954440  22.021681  6.293862  251.621316\n",
              "51      50     1  15.384080  367.483779  19.169866  5.356815  252.436677\n",
              "52      50     2  18.232893  499.372681  22.346648  6.402841  257.872724\n",
              "53      50     3  14.916967  347.196082  18.633198  5.203986  244.957552\n",
              "54      50     4  18.470940  514.403258  22.680460  6.488050  237.322231\n",
              "55      50     5  17.079273  443.215384  21.052681  5.995001  209.100802\n",
              "56      50     6  14.881234  343.470972  18.532970  5.169321  237.912954\n",
              "57      50     7  15.912704  390.033434  19.749264  5.561161  242.270167\n",
              "58      50     8  17.353007  457.300828  21.384593  6.102271  233.682414\n",
              "59      50     9  16.538022  419.686285  20.486246  5.791815  251.837168"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch_test_finetuning = pd.read_csv('epoch_finetune_data/finetuning_test_data.csv')\n",
        "epoch_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#epoch</th>\n",
              "      <th>#try</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>train_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.00000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>50.0</td>\n",
              "      <td>4.50000</td>\n",
              "      <td>16.670705</td>\n",
              "      <td>426.711714</td>\n",
              "      <td>20.605761</td>\n",
              "      <td>5.836512</td>\n",
              "      <td>241.901400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.02765</td>\n",
              "      <td>1.351747</td>\n",
              "      <td>63.002699</td>\n",
              "      <td>1.532730</td>\n",
              "      <td>0.494784</td>\n",
              "      <td>13.940568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>50.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>14.881234</td>\n",
              "      <td>343.470972</td>\n",
              "      <td>18.532970</td>\n",
              "      <td>5.169321</td>\n",
              "      <td>209.100802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>50.0</td>\n",
              "      <td>2.25000</td>\n",
              "      <td>15.516236</td>\n",
              "      <td>373.121193</td>\n",
              "      <td>19.314716</td>\n",
              "      <td>5.407902</td>\n",
              "      <td>237.469912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.0</td>\n",
              "      <td>4.50000</td>\n",
              "      <td>16.808647</td>\n",
              "      <td>431.450834</td>\n",
              "      <td>20.769464</td>\n",
              "      <td>5.893408</td>\n",
              "      <td>243.613860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.0</td>\n",
              "      <td>6.75000</td>\n",
              "      <td>17.791700</td>\n",
              "      <td>478.041037</td>\n",
              "      <td>21.862409</td>\n",
              "      <td>6.245964</td>\n",
              "      <td>251.783205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>50.0</td>\n",
              "      <td>9.00000</td>\n",
              "      <td>18.470940</td>\n",
              "      <td>514.403258</td>\n",
              "      <td>22.680460</td>\n",
              "      <td>6.488050</td>\n",
              "      <td>257.872724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       #epoch      #try        MAE         MSE       RMSE       MAPE  \\\n",
              "count    10.0  10.00000  10.000000   10.000000  10.000000  10.000000   \n",
              "mean     50.0   4.50000  16.670705  426.711714  20.605761   5.836512   \n",
              "std       0.0   3.02765   1.351747   63.002699   1.532730   0.494784   \n",
              "min      50.0   0.00000  14.881234  343.470972  18.532970   5.169321   \n",
              "25%      50.0   2.25000  15.516236  373.121193  19.314716   5.407902   \n",
              "50%      50.0   4.50000  16.808647  431.450834  20.769464   5.893408   \n",
              "75%      50.0   6.75000  17.791700  478.041037  21.862409   6.245964   \n",
              "max      50.0   9.00000  18.470940  514.403258  22.680460   6.488050   \n",
              "\n",
              "       train_time  \n",
              "count   10.000000  \n",
              "mean   241.901400  \n",
              "std     13.940568  \n",
              "min    209.100802  \n",
              "25%    237.469912  \n",
              "50%    243.613860  \n",
              "75%    251.783205  \n",
              "max    257.872724  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch5 = epoch_test_finetuning[50:60]\n",
        "epoch5.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>#epoch</th>\n",
              "      <th>5</th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>40</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#try</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.422650</td>\n",
              "      <td>21.925709</td>\n",
              "      <td>19.038973</td>\n",
              "      <td>20.986296</td>\n",
              "      <td>21.605176</td>\n",
              "      <td>22.021681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.367137</td>\n",
              "      <td>20.048188</td>\n",
              "      <td>20.546504</td>\n",
              "      <td>19.931607</td>\n",
              "      <td>21.482426</td>\n",
              "      <td>19.169866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.538107</td>\n",
              "      <td>19.387756</td>\n",
              "      <td>23.663993</td>\n",
              "      <td>19.450284</td>\n",
              "      <td>19.227749</td>\n",
              "      <td>22.346648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.294729</td>\n",
              "      <td>18.514197</td>\n",
              "      <td>20.009697</td>\n",
              "      <td>20.767412</td>\n",
              "      <td>19.243231</td>\n",
              "      <td>18.633198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.320069</td>\n",
              "      <td>21.950618</td>\n",
              "      <td>18.628566</td>\n",
              "      <td>20.048082</td>\n",
              "      <td>20.324311</td>\n",
              "      <td>22.680460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18.901558</td>\n",
              "      <td>19.118082</td>\n",
              "      <td>20.346684</td>\n",
              "      <td>18.930889</td>\n",
              "      <td>18.429901</td>\n",
              "      <td>21.052681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20.386883</td>\n",
              "      <td>21.312811</td>\n",
              "      <td>22.573524</td>\n",
              "      <td>20.893638</td>\n",
              "      <td>23.090616</td>\n",
              "      <td>18.532970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19.964481</td>\n",
              "      <td>19.075517</td>\n",
              "      <td>18.654510</td>\n",
              "      <td>24.572496</td>\n",
              "      <td>20.218544</td>\n",
              "      <td>19.749264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>21.475673</td>\n",
              "      <td>18.472002</td>\n",
              "      <td>22.011396</td>\n",
              "      <td>18.993428</td>\n",
              "      <td>21.808539</td>\n",
              "      <td>21.384593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26.019420</td>\n",
              "      <td>20.204186</td>\n",
              "      <td>21.392407</td>\n",
              "      <td>18.866895</td>\n",
              "      <td>19.441489</td>\n",
              "      <td>20.486246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "#epoch         5          10         20         30         40         50\n",
              "#try                                                                    \n",
              "0       20.422650  21.925709  19.038973  20.986296  21.605176  22.021681\n",
              "1       18.367137  20.048188  20.546504  19.931607  21.482426  19.169866\n",
              "2       25.538107  19.387756  23.663993  19.450284  19.227749  22.346648\n",
              "3       20.294729  18.514197  20.009697  20.767412  19.243231  18.633198\n",
              "4       20.320069  21.950618  18.628566  20.048082  20.324311  22.680460\n",
              "5       18.901558  19.118082  20.346684  18.930889  18.429901  21.052681\n",
              "6       20.386883  21.312811  22.573524  20.893638  23.090616  18.532970\n",
              "7       19.964481  19.075517  18.654510  24.572496  20.218544  19.749264\n",
              "8       21.475673  18.472002  22.011396  18.993428  21.808539  21.384593\n",
              "9       26.019420  20.204186  21.392407  18.866895  19.441489  20.486246"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch_test_finetune_rmse = epoch_test_finetuning.pivot(index='#try', columns='#epoch', values='RMSE')\n",
        "epoch_test_finetune_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.boxplot(epoch_test_finetune_rmse)\n",
        "ax.set_xticklabels(['5', '10', '20', '30', '40', '50'])\n",
        "ax.set_title(\"Boxplot Hasil Fine Tuning Parameter Epoch\")\n",
        "ax.set_xlabel('Number of epochs')\n",
        "ax.set_ylabel('RMSE Values (lower is better)')\n",
        "plt.savefig('epoch_finetune_data/epoch_boxplot.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_history_finetuning = pd.DataFrame(epoch_finetune_history, columns=['#epoch', '#try', 'loss', 'val_loss', 'mae', 'val_mae', 'train_time'])\n",
        "epoch_history_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_history_finetuning.to_csv('neuron_finetune_data/finetuning_history_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neuron Number Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_final = 10\n",
        "neurons = [16, 32, 64, 128]\n",
        "\n",
        "neuron_finetune_history = []\n",
        "neuron_finetune_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = dataset_df[['Close', 'Compound']].copy()\n",
        "\n",
        "train_portion = 0.8\n",
        "timestep = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(neurons)):\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    ax.set_title('Loss value for ' + str(neurons[i]) + ' neurons')\n",
        "    ax.set_xlabel('epochs')\n",
        "    ax.set_ylabel('error value')\n",
        "    ax.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax.yaxis.grid(True, alpha=0.5)\n",
        "\n",
        "    for j in range(20):\n",
        "\n",
        "        x_train, y_train, x_test, y_test, scaler = SplitData(combined_data, train_portion, timestep)\n",
        "\n",
        "        start_time = time.time()\n",
        "        sentimentModel, history = TrainModelFineTune(x_train, y_train, epoch_final, neurons[i])\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "\n",
        "        predictions = sentimentModel.predict(x_test)\n",
        "        predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "        mae = np.mean(np.abs(predictions - y_test))\n",
        "        mse = np.mean((predictions - y_test)**2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = np.mean(np.abs((y_test - predictions)/y_test)) * 100\n",
        "\n",
        "        neuron_finetune_test.append([neurons[i], j, mae, mse, rmse, mape, training_time])\n",
        "\n",
        "        history_data = history.history\n",
        "    \n",
        "        loss_values = history_data['loss']\n",
        "        val_loss_values = history_data['val_loss']\n",
        "\n",
        "        neuron_finetune_history.append([neurons[i], j, history_data['loss'], history_data['val_loss'], history_data['mae'], history_data['val_mae'], training_time])\n",
        "\n",
        "        ax.plot(loss_values, color = 'blue')\n",
        "        ax.plot(val_loss_values, color='red')\n",
        "\n",
        "    plt.savefig('neuron_finetune_data/'+ str(neurons[i]) +'_neuron_diagnostic.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_test_finetuning = pd.DataFrame(neuron_finetune_test, columns=['#neuron', '#try', 'MAE', 'MSE', 'RMSE', 'MAPE', 'train_time'])\n",
        "neuron_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_test_finetuning.to_csv('neuron_finetune_data/finetuning_test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_test_finetuning = pd.read_csv('neuron_finetune_data/finetuning_test_data.csv')\n",
        "neuron_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = neuron_test_finetuning[60:80]\n",
        "y.drop(60).drop(67).drop(75).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_test_finetune_rmse = neuron_test_finetuning.pivot(index='#try', columns='#neuron', values='RMSE')\n",
        "neuron_test_finetune_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.boxplot(neuron_test_finetune_rmse)\n",
        "ax.set_xticklabels(['16', '32', '64', '128'])\n",
        "ax.set_title(\"Boxplot Hasil Fine Tuning Parameter LSTM Unit\")\n",
        "ax.set_xlabel('Number of neurons')\n",
        "ax.set_ylabel('RMSE Values (lower is better)')\n",
        "plt.savefig('neuron_finetune_data/neuron_boxplot.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_history_finetuning = pd.DataFrame(neuron_finetune_history, columns=['#neuron', '#try', 'loss', 'val_loss', 'mae', 'val_mae', 'train_time'])\n",
        "neuron_history_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_history_finetuning.to_csv('neuron_finetune_data/finetuning_history_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_history_finetuning = pd.read_csv('neuron_finetune_data/finetuning_history_data.csv')\n",
        "neuron_history_finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COMPARE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mode = ['single', 'combined']\n",
        "\n",
        "compare_finetune_history = []\n",
        "compare_finetune_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "single_data = dataset_df['Close']\n",
        "combined_data = dataset_df[['Close', 'Compound']].copy()\n",
        "\n",
        "train_portion = 0.8\n",
        "timestep = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(model_mode)):\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    ax.set_title('Loss value for ' + str(model_mode[i]) + ' mode')\n",
        "    ax.set_xlabel('epochs')\n",
        "    ax.set_ylabel('error value')\n",
        "    ax.xaxis.grid(True, which='both', alpha=0.5)\n",
        "    ax.yaxis.grid(True, alpha=0.5)\n",
        "\n",
        "    for j in range(30):\n",
        "        \n",
        "        if (model_mode == 'single'):\n",
        "            x_train, y_train, x_test, y_test, scaler = SplitData(single_data, train_portion, timestep)\n",
        "        else:\n",
        "            x_train, y_train, x_test, y_test, scaler = SplitData(combined_data, train_portion, timestep)\n",
        "\n",
        "        start_time = time.time()\n",
        "        sentimentModel, history = TrainModelFineTune(x_train, y_train, 10, 64)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "\n",
        "        predictions = sentimentModel.predict(x_test)\n",
        "        predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "        mae = np.mean(np.abs(predictions - y_test))\n",
        "        mse = np.mean((predictions - y_test)**2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = np.mean(np.abs((y_test - predictions)/y_test)) * 100\n",
        "\n",
        "        compare_finetune_test.append([model_mode[i], j, mae, mse, rmse, mape, training_time])\n",
        "\n",
        "        history_data = history.history\n",
        "    \n",
        "        loss_values = history_data['loss']\n",
        "        val_loss_values = history_data['val_loss']\n",
        "\n",
        "        compare_finetune_history.append([model_mode[i], j, history_data['loss'], history_data['val_loss'], history_data['mae'], history_data['val_mae'], training_time])\n",
        "\n",
        "        ax.plot(loss_values, color = 'blue')\n",
        "        ax.plot(val_loss_values, color='red')\n",
        "\n",
        "    plt.savefig('compare_finetune_data/'+ str(model_mode[i]) +'_mode_diagnostic.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_test_finetuning = pd.DataFrame(compare_finetune_test, columns=['mode', '#try', 'MAE', 'MSE', 'RMSE', 'MAPE', 'train_time'])\n",
        "compare_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_test_finetuning.to_csv('compare_finetune_data/finetuning_test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_test_finetuning = pd.read_csv('compare_finetune_data/finetuning_test_data.csv')\n",
        "compare_test_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xyz = compare_test_finetuning[30:60]\n",
        "xyz.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_test_finetune_rmse = compare_test_finetuning.pivot(index='#try', columns='mode', values='RMSE')\n",
        "compare_test_finetune_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.boxplot(compare_test_finetune_rmse)\n",
        "ax.set_xticklabels(['Combined Dataset', 'Single Dataset'])\n",
        "ax.set_title(\"Perbandingan Model untuk Combined Dataset vs Single Dataset\")\n",
        "ax.set_ylabel('RMSE Values (lower is better)')\n",
        "ax.grid()\n",
        "plt.savefig('compare_finetune_data/comparison_boxplot.png', facecolor=(1, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_history_finetuning = pd.DataFrame(compare_finetune_history, columns=['mode', '#try', 'loss', 'val_loss', 'mae', 'val_mae', 'train_time'])\n",
        "compare_history_finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_history_finetuning.to_csv('compare_finetune_data/finetuning_history_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare_history_finetuning = pd.read_csv('compare_finetune_data/finetuning_history_data.csv')\n",
        "compare_history_finetuning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
